#!/usr/bin/perl

# s3 command - script for manipulating files on Amazon AWS S3 service

# Copyright (c) 2008, Oliver Crow
# See License.txt for terms of use

use Net::Amazon::S3;
use Text::Wrap;
use File::stat;
use File::Spec;
use strict;

my $VERSION = 0.5;

my (%config, $s3, $cmd);

sub usage_quit {
    my ($message) = @_;
    print "\n$message\n" unless ($message eq '');
    print "\nusage: $0 <command> [parameters]\n";
    print "commands:\n";
    print "   ls                            - list buckets\n";
    print "   ls   <bucket>[/<path>]        - list files\n";
    print "   ll   <bucket>[/<path>]        - list files in long format\n";
    print "   get  <bucket>[/<path>] <file> - get file from S3\n";
    print "   put  <bucket>[/<path>] <file> - put file to S3\n";
    print "   push <bucket>[/<path>] <file> "
        . "- put file to S3 if it has changed locally\n";
    print "   rm   <bucket>[/<path>] <file> - remove a file from S3\n";
    print "   info <bucket>[/<path>] <file> - display metadata for a file in S3\n";
    print "   diff <bucket>[/<path>] <file> "
        . "- compare local file with stored S3 checksum\n";
    print "   mkbucket <bucket>             - create a bucket\n";
    print "   rmbucket <bucket>             - remove an empty bucket\n";
    print "\n";
    exit(1);
}

sub argv_location {
    # get a bucket name, and optional path
    # and a file name from the command arguments, or die
    if (scalar(@ARGV) == 0) {
        error("usage: $0 $cmd <bucket>[/<path>]");
    }
    my $location = shift @ARGV;
    my ($bucket, $path) = split(/\//, $location, 2);

    if ($bucket eq '') {
        error("Bucket name cannot begin with '\/'")
            if ($location =~ /^\//);
        error("Please specify a bucket name");
    }

    # make sure path ends with /
    if ($path ne '' && substr($path, -1, 1) ne '/') {
        $path .= '/';
    }
    return ($bucket, $path);
}

sub argv_location_and_file {
    # get a bucket, path and file from argv
    # derive the S3 key from the path and file
    # return the bucket, key and file

    # get a bucket and file name from the command arguments, or die
    if (scalar(@ARGV) < 2) {
        error("usage: $0 $cmd <bucket>[/<path>] <file>");
    }

    my ($bucket, $path) = argv_location();

    # get the filename part from the file path
    my ($file) = shift @ARGV;
    my ($volume, $dir, $fname) = File::Spec->splitpath($file);
    my $key = $path . $fname;
    return ($bucket, $key, $file);
}

sub argv_bucket_name {
    # get a bucket name from the command arguments, or die
    if (scalar(@ARGV) == 0) {
        error("usage: $0 $cmd <bucket>");
    }
    my ($bucket) = split(/\//, shift @ARGV);
    return $bucket;
}

sub get_config {
    my $rcfile = "$ENV{'HOME'}/.s3rc";
    open RC, $rcfile
        or die "Couldn't open config file '$rcfile'";
    while(<RC>) {
        m/(\S+)\s*:\s*(\S+)/;
        $config{$1} = $2 if (defined $1);
    }
    close RC;
    if (!defined($config{'aws_access_key_id'})) {
        die "Config file didn't define aws_access_key_id";
    }
    if (!defined($config{'aws_secret_access_key'})) {
        die "Config file didn't define aws_secret_access_key";
    }
}

sub open_s3 {
    $s3 = Net::Amazon::S3->new({
        aws_access_key_id => $config{'aws_access_key_id'},
        aws_secret_access_key => $config{'aws_secret_access_key'},
        retry => 1
    });
}

sub s3_error {
    print "S3 Error: " . $s3->err . "\n";
    print wrap("", "", $s3->errstr) . "\n";
    exit(1);
}

sub error {
    my ($msg) = @_;
    print STDERR $msg . "\n";
    exit(1);
}

sub list_files { 
    # list files in given location
    my ($bucket_name, $path) = argv_location();
    my %params;

    my $response = $s3->list_bucket_all({
        'bucket' => $bucket_name,
        'prefix' => $path,
        'delimiter' => '/',
    }) or s3_error();

    exists $response->{bucket}
        or error("No such bucket '$bucket_name'");

    foreach my $k (@{$response->{common_prefixes}}) {
        print $k . "/\n";
    }

    foreach my $key (@{$response->{keys}}) {
        my $name = $key->{key};

        # strip off the path from the results
        if (index($name, $path) == 0) {
            $name = substr($name, length($path));
        }
        if ($cmd eq 'll') {
            my $date = $key->{last_modified};
            $date =~ s/T/ /; $date =~ s/\.\d\d\dZ//;
            printf("%10d  %s  %s\n", 
                $key->{size}, $date, $name);
        } else {
            printf("%s\n", $name);
        }
    }
}

sub list_buckets {
    my $buckets = $s3->buckets
        or s3_error();
    foreach my $bucket (@{$buckets->{buckets}}) {
        print $bucket->bucket . "\n";
    }
}

sub show_list {
    if (scalar(@ARGV) > 0) {
        list_files();
    } else {
        list_buckets();
    }
}

sub get_file { 
    my ($bucket_name, $key, $file) = argv_location_and_file();

    my $bucket=$s3->bucket($bucket_name);
    my $meta_data = $bucket->head_key($key)
        or error("No such file '$key'");

    # don't clobber local file
    ! -e $file or error("File '$file' already exists");

    # get file contents
    $bucket->get_key_filename($key, "GET", $file)
        or error("No such file '$key'");

    my $remote_mtime = $meta_data->{'x-amz-meta-file-mtime'};
    if (defined($remote_mtime)) {
        utime time, $remote_mtime, $file;
    }
}

sub get_files {
    my ($bucket_name) = shift;
    my ($key) = shift;
    
}

sub put_file {
    my ($bucket_name, $key, $file) = argv_location_and_file();
    send_file($bucket_name, $key, $file);
}

sub send_file { 
    my ($bucket_name, $key, $file) = @_;

    -f $file or error("No such file '$file'");
    -r $file or error("Can't read file '$file'");

    # get file modification date
    my $mtime = (stat $file)->mtime;

    my $bucket=$s3->bucket($bucket_name);

    if (-z $file) {
        # special case for empty files
        $bucket->add_key($key, "", 
            {'x-amz-meta-file-mtime' => $mtime})
            or s3_error();
    } else {
        $bucket->add_key_filename($key, $file, 
            {'x-amz-meta-file-mtime' => $mtime})
            or s3_error();
    }
}

sub new_version {
    # find an unused version number to upload for a file that already
    # exists in s3

    my ($bucket_name, $key) = @_;

    

}

sub push_file {
    # send file to S3 if it isn't already there 
    # if it has changed, as determined by file size and modification date 
    # send the new version (keeping the previous version intact)

    my ($bucket_name, $key, $file) = argv_location_and_file();

    -f $file or error("File '$file' doesn't exist locally");
    -r $file or error("File '$file' isn't readable");

    my $bucket=$s3->bucket($bucket_name);
    my $meta_data = $bucket->head_key($key);

    # file doesn't exist on S3, so send it
    if (!defined($meta_data)) {
        send_file($bucket_name, $key, $file);
        return;
    }
    
    # compare local and remote file sizes and modification times
    my $local_size = (-s $file);
    my $local_mtime = (stat $file)->mtime;

    my $remote_size = $meta_data->{content_length};
    my $remote_mtime = $meta_data->{'x-amz-meta-file-mtime'};

    if ($local_size != $remote_size || $local_mtime ne $remote_mtime) {
        print "bucket: $bucket_name\nkey: $key\nfile: $file\n";
        # send_file($bucket_name, $key, $file);
        return;
    }
    exit(2);
}

sub remove_file { 
    my ($bucket_name, $key, $file) = argv_location_and_file();
    
    my $bucket=$s3->bucket($bucket_name);
    $bucket->delete_key($key)
        or s3_error();
} 

sub file_info {
    my ($bucket_name, $key, $file) = argv_location_and_file();
    my $bucket=$s3->bucket($bucket_name);
    my $meta_data = $bucket->head_key($key);

    if (!defined($meta_data)) { 
        error("File '$key' doesn't exist in $bucket_name"); 
    }
    foreach my $field (keys %$meta_data) {
        print "$field: $meta_data->{$field}\n" 
            unless ($field eq "value");
    }
}

sub diff_file {
    # compare local file with version on S3 using file sizes and MD5 checksums
    # to determine if the files differ
    use Digest::MD5;
    my ($bucket_name, $key, $file) = argv_location_and_file();
    
    -f $file or error("File '$file' doesn't exist locally");
    -r $file or error("File '$file' isn't readable");

    my $bucket=$s3->bucket($bucket_name);
    my $meta_data = $bucket->head_key($key);

    defined($meta_data) or error("File '$key' doesn't exist on S3"); 

    # compare file sizes
    my $local_size = (-s $file);
    my $remote_size = $meta_data->{content_length};

    if ($local_size != $remote_size) {
        printf STDERR "Files differ in size\nlocal:  %10d\nremote: %10d\n", 
            $local_size, $remote_size;
        exit(2);
    }

    # compare MD5 checksums
    my $remote_md5 = $meta_data->{etag};
    open FILE, $file or error("Can't read file '$file': $!");
    binmode FILE;
    my $md5 = Digest::MD5->new;
    $md5->addfile(*FILE);
    my $local_md5 = $md5->hexdigest;

    if ($local_md5 ne $remote_md5) {
        printf STDERR "File checksums differ\nlocal:  %s\nremote: %s\n",
            $local_md5, $remote_md5;
        exit(2);
    }
}

sub make_bucket {
    my $bucket_name = argv_bucket_name();
    $s3->add_bucket( { bucket => $bucket_name } ) or s3_error();
}

sub remove_bucket { 
    my $bucket_name = argv_bucket_name();
    my $bucket=$s3->bucket($bucket_name);
    $bucket->delete_bucket or s3_error();
}

my %commands = (
    'ls'   => \&show_list,
    'll'   => \&show_list,
    'info' => \&file_info,
    'get'  => \&get_file,
    'put'  => \&put_file,
    'push' => \&push_file,
    'rm'   => \&remove_file,
    'diff' => \&diff_file,
    'mkbucket' => \&make_bucket,
    'rmbucket' => \&remove_bucket,
);

$cmd = shift @ARGV;
if (!defined($cmd)) {
    usage_quit();
}

get_config();
open_s3();

if (defined($commands{$cmd})) {
    $commands{$cmd}->();
} else {
    print STDERR "Unknown command '$cmd'\n";
    exit(1);
}


=head1 NAME

Some stuff

=head1 DESCRIPTION



=pod SCRIPT_CATEGORIES

Networking

=pod PREREQUISITES

Net::Amazon::S3;

=cut


